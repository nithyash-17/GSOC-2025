{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nithyash-17/GSOC-2025/blob/main/GSOC_Task_7_Vision_Transformer_Quantum_Vision_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!pip install tensorflow==2.15.0 tensorflow-quantum==0.7.3 cirq\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xb4E6nABfukc",
        "outputId": "7f789b78-68a9-4173-afd1-d79e06f1a6a9"
      },
      "id": "Xb4E6nABfukc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.15.0\n",
            "  Downloading tensorflow-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Collecting tensorflow-quantum==0.7.3\n",
            "  Downloading tensorflow_quantum-0.7.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting cirq\n",
            "  Downloading cirq-1.4.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.13.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (18.1.1)\n",
            "Collecting ml-dtypes~=0.2.0 (from tensorflow==2.15.0)\n",
            "  Downloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting numpy<2.0.0,>=1.23.5 (from tensorflow==2.15.0)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m392.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (24.2)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.15.0)\n",
            "  Downloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (4.12.2)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.15.0)\n",
            "  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.71.0)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow==2.15.0)\n",
            "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow==2.15.0)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.16,>=2.15.0 (from tensorflow==2.15.0)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting cirq-core==1.3.0 (from tensorflow-quantum==0.7.3)\n",
            "  Downloading cirq_core-1.3.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting cirq-google==1.3.0 (from tensorflow-quantum==0.7.3)\n",
            "  Downloading cirq_google-1.3.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting sympy==1.12 (from tensorflow-quantum==0.7.3)\n",
            "  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting duet~=0.2.8 (from cirq-core==1.3.0->tensorflow-quantum==0.7.3)\n",
            "  Downloading duet-0.2.9-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.11/dist-packages (from cirq-core==1.3.0->tensorflow-quantum==0.7.3) (3.10.0)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.11/dist-packages (from cirq-core==1.3.0->tensorflow-quantum==0.7.3) (3.4.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from cirq-core==1.3.0->tensorflow-quantum==0.7.3) (2.2.2)\n",
            "Requirement already satisfied: sortedcontainers~=2.0 in /usr/local/lib/python3.11/dist-packages (from cirq-core==1.3.0->tensorflow-quantum==0.7.3) (2.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from cirq-core==1.3.0->tensorflow-quantum==0.7.3) (1.14.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from cirq-core==1.3.0->tensorflow-quantum==0.7.3) (4.67.1)\n",
            "Requirement already satisfied: google-api-core>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]>=1.14.0->cirq-google==1.3.0->tensorflow-quantum==0.7.3) (2.24.2)\n",
            "Requirement already satisfied: proto-plus>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from cirq-google==1.3.0->tensorflow-quantum==0.7.3) (1.26.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy==1.12->tensorflow-quantum==0.7.3) (1.3.0)\n",
            "Collecting cirq-aqt==1.4.1 (from cirq)\n",
            "  Downloading cirq_aqt-1.4.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "INFO: pip is looking at multiple versions of cirq to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting cirq\n",
            "  Downloading cirq-1.4.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting cirq-aqt==1.4.0 (from cirq)\n",
            "  Downloading cirq_aqt-1.4.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting cirq\n",
            "  Downloading cirq-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting cirq-aqt==1.3.0 (from cirq)\n",
            "  Downloading cirq_aqt-1.3.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting cirq-ft==1.3.0 (from cirq)\n",
            "  Downloading cirq_ft-1.3.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting cirq-ionq==1.3.0 (from cirq)\n",
            "  Downloading cirq_ionq-1.3.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting cirq-pasqal==1.3.0 (from cirq)\n",
            "  Downloading cirq_pasqal-1.3.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting cirq-rigetti==1.3.0 (from cirq)\n",
            "  Downloading cirq_rigetti-1.3.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting cirq-web==1.3.0 (from cirq)\n",
            "  Downloading cirq_web-1.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: requests~=2.18 in /usr/local/lib/python3.11/dist-packages (from cirq-aqt==1.3.0->cirq) (2.32.3)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from cirq-ft==1.3.0->cirq) (25.3.0)\n",
            "Requirement already satisfied: cachetools>=5.3 in /usr/local/lib/python3.11/dist-packages (from cirq-ft==1.3.0->cirq) (5.5.2)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (from cirq-ft==1.3.0->cirq) (7.7.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.11/dist-packages (from cirq-ft==1.3.0->cirq) (7.16.6)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from cirq-ft==1.3.0->cirq) (5.10.4)\n",
            "Collecting pyquil<4.0.0,>=3.2.0 (from cirq-rigetti==1.3.0->cirq)\n",
            "  Downloading pyquil-3.5.4-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.45.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.1.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core>=1.14.0->google-api-core[grpc]>=1.14.0->cirq-google==1.3.0->tensorflow-quantum==0.7.3) (1.69.2)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]>=1.14.0->cirq-google==1.3.0->tensorflow-quantum==0.7.3) (1.71.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.0.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->cirq-core==1.3.0->tensorflow-quantum==0.7.3) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->cirq-core==1.3.0->tensorflow-quantum==0.7.3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->cirq-core==1.3.0->tensorflow-quantum==0.7.3) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->cirq-core==1.3.0->tensorflow-quantum==0.7.3) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->cirq-core==1.3.0->tensorflow-quantum==0.7.3) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->cirq-core==1.3.0->tensorflow-quantum==0.7.3) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->cirq-core==1.3.0->tensorflow-quantum==0.7.3) (2.8.2)\n",
            "Requirement already satisfied: deprecated<2.0.0,>=1.2.13 in /usr/local/lib/python3.11/dist-packages (from pyquil<4.0.0,>=3.2.0->cirq-rigetti==1.3.0->cirq) (1.2.18)\n",
            "Collecting lark<0.12.0,>=0.11.1 (from pyquil<4.0.0,>=3.2.0->cirq-rigetti==1.3.0->cirq)\n",
            "  Downloading lark-0.11.3.tar.gz (229 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting qcs-api-client<0.22.0,>=0.21.0 (from pyquil<4.0.0,>=3.2.0->cirq-rigetti==1.3.0->cirq)\n",
            "  Downloading qcs_api_client-0.21.6-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting rpcq<4.0.0,>=3.10.0 (from pyquil<4.0.0,>=3.2.0->cirq-rigetti==1.3.0->cirq)\n",
            "  Downloading rpcq-3.11.0.tar.gz (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tenacity<9.0.0,>=8.2.2 (from pyquil<4.0.0,>=3.2.0->cirq-rigetti==1.3.0->cirq)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting types-deprecated<2.0.0.0,>=1.2.9.2 (from pyquil<4.0.0,>=3.2.0->cirq-rigetti==1.3.0->cirq)\n",
            "  Downloading types_deprecated-1.2.15.20250304-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting types-python-dateutil<3.0.0,>=2.8.19 (from pyquil<4.0.0,>=3.2.0->cirq-rigetti==1.3.0->cirq)\n",
            "  Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting types-retry<0.10.0,>=0.9.9 (from pyquil<4.0.0,>=3.2.0->cirq-rigetti==1.3.0->cirq)\n",
            "  Downloading types_retry-0.9.9.20250322-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests~=2.18->cirq-aqt==1.3.0->cirq) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests~=2.18->cirq-aqt==1.3.0->cirq) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests~=2.18->cirq-aqt==1.3.0->cirq) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests~=2.18->cirq-aqt==1.3.0->cirq) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.2)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->cirq-ft==1.3.0->cirq) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->cirq-ft==1.3.0->cirq) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->cirq-ft==1.3.0->cirq) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->cirq-ft==1.3.0->cirq) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->cirq-ft==1.3.0->cirq) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->cirq-ft==1.3.0->cirq) (3.0.13)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert->cirq-ft==1.3.0->cirq) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->cirq-ft==1.3.0->cirq) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert->cirq-ft==1.3.0->cirq) (0.7.1)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->cirq-ft==1.3.0->cirq) (3.1.6)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.11/dist-packages (from nbconvert->cirq-ft==1.3.0->cirq) (5.7.2)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert->cirq-ft==1.3.0->cirq) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert->cirq-ft==1.3.0->cirq) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert->cirq-ft==1.3.0->cirq) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert->cirq-ft==1.3.0->cirq) (1.5.1)\n",
            "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert->cirq-ft==1.3.0->cirq) (2.18.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->cirq-ft==1.3.0->cirq) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->cirq-ft==1.3.0->cirq) (4.23.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->cirq-core==1.3.0->tensorflow-quantum==0.7.3) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->cirq-core==1.3.0->tensorflow-quantum==0.7.3) (2025.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->cirq-ft==1.3.0->cirq) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert->cirq-ft==1.3.0->cirq) (1.4.0)\n",
            "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]>=1.14.0->cirq-google==1.3.0->tensorflow-quantum==0.7.3)\n",
            "  Downloading grpcio_status-1.70.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.69.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.68.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.68.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.67.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.67.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.66.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "INFO: pip is still looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading grpcio_status-1.66.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.66.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.65.5-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.65.4-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.65.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading grpcio_status-1.65.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.64.3-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.64.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.64.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.63.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.63.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.62.3-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->cirq-ft==1.3.0->cirq) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->cirq-ft==1.3.0->cirq) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->cirq-ft==1.3.0->cirq) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->cirq-ft==1.3.0->cirq) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->cirq-ft==1.3.0->cirq) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->cirq-ft==1.3.0->cirq) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->cirq-ft==1.3.0->cirq) (6.4.2)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets->cirq-ft==1.3.0->cirq)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->cirq-ft==1.3.0->cirq) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->cirq-ft==1.3.0->cirq) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->cirq-ft==1.3.0->cirq) (3.0.50)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->cirq-ft==1.3.0->cirq) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->cirq-ft==1.3.0->cirq) (4.9.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->cirq-ft==1.3.0->cirq) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->cirq-ft==1.3.0->cirq) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->cirq-ft==1.3.0->cirq) (0.23.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.7->nbconvert->cirq-ft==1.3.0->cirq) (4.3.7)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.6.1)\n",
            "Requirement already satisfied: PyJWT<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from qcs-api-client<0.22.0,>=0.21.0->pyquil<4.0.0,>=3.2.0->cirq-rigetti==1.3.0->cirq) (2.10.1)\n",
            "INFO: pip is looking at multiple versions of qcs-api-client to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting qcs-api-client<0.22.0,>=0.21.0 (from pyquil<4.0.0,>=3.2.0->cirq-rigetti==1.3.0->cirq)\n",
            "  Downloading qcs_api_client-0.21.5-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading qcs_api_client-0.21.4-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading qcs_api_client-0.21.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading qcs_api_client-0.21.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading qcs_api_client-0.21.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading qcs_api_client-0.21.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting jsonschema>=2.6 (from nbformat->cirq-ft==1.3.0->cirq)\n",
            "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "INFO: pip is still looking at multiple versions of qcs-api-client to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading jsonschema-4.22.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "  Downloading jsonschema-4.21.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "  Downloading jsonschema-4.21.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "  Downloading jsonschema-4.20.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "  Downloading jsonschema-4.19.2-py3-none-any.whl.metadata (7.9 kB)\n",
            "  Downloading jsonschema-4.19.1-py3-none-any.whl.metadata (7.9 kB)\n",
            "  Downloading jsonschema-4.19.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "  Downloading jsonschema-4.18.6-py3-none-any.whl.metadata (7.8 kB)\n",
            "  Downloading jsonschema-4.18.5-py3-none-any.whl.metadata (7.7 kB)\n",
            "  Downloading jsonschema-4.18.4-py3-none-any.whl.metadata (7.8 kB)\n",
            "  Downloading jsonschema-4.18.3-py3-none-any.whl.metadata (7.9 kB)\n",
            "  Downloading jsonschema-4.18.2-py3-none-any.whl.metadata (7.8 kB)\n",
            "  Downloading jsonschema-4.18.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "  Downloading jsonschema-4.18.0-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading jsonschema-4.17.3-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 (from jsonschema>=2.6->nbformat->cirq-ft==1.3.0->cirq)\n",
            "  Downloading pyrsistent-0.20.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
            "Collecting attrs (from cirq-ft==1.3.0->cirq)\n",
            "  Downloading attrs-21.4.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting httpx<0.24.0,>=0.23.0 (from qcs-api-client<0.22.0,>=0.21.0->pyquil<4.0.0,>=3.2.0->cirq-rigetti==1.3.0->cirq)\n",
            "  Downloading httpx-0.23.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting iso8601<2.0.0,>=1.0.2 (from qcs-api-client<0.22.0,>=0.21.0->pyquil<4.0.0,>=3.2.0->cirq-rigetti==1.3.0->cirq)\n",
            "  Downloading iso8601-1.1.0-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting pydantic<2.0.0,>=1.7.2 (from qcs-api-client<0.22.0,>=0.21.0->pyquil<4.0.0,>=3.2.0->cirq-rigetti==1.3.0->cirq)\n",
            "  Downloading pydantic-1.10.21-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.9/153.9 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting retrying<2.0.0,>=1.3.3 (from qcs-api-client<0.22.0,>=0.21.0->pyquil<4.0.0,>=3.2.0->cirq-rigetti==1.3.0->cirq)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting rfc3339<7.0,>=6.2 (from qcs-api-client<0.22.0,>=0.21.0->pyquil<4.0.0,>=3.2.0->cirq-rigetti==1.3.0->cirq)\n",
            "  Downloading rfc3339-6.2-py3-none-any.whl.metadata (816 bytes)\n",
            "Requirement already satisfied: toml<0.11.0,>=0.10.2 in /usr/local/lib/python3.11/dist-packages (from qcs-api-client<0.22.0,>=0.21.0->pyquil<4.0.0,>=3.2.0->cirq-rigetti==1.3.0->cirq) (0.10.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.2.2)\n",
            "Requirement already satisfied: msgpack<2.0,>=0.6 in /usr/local/lib/python3.11/dist-packages (from rpcq<4.0.0,>=3.10.0->pyquil<4.0.0,>=3.2.0->cirq-rigetti==1.3.0->cirq) (1.1.0)\n",
            "Collecting python-rapidjson (from rpcq<4.0.0,>=3.10.0->pyquil<4.0.0,>=3.2.0->cirq-rigetti==1.3.0->cirq)\n",
            "  Downloading python_rapidjson-1.20-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting ruamel.yaml (from rpcq<4.0.0,>=3.10.0->pyquil<4.0.0,>=3.2.0->cirq-rigetti==1.3.0->cirq)\n",
            "  Downloading ruamel.yaml-0.18.10-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->cirq-ft==1.3.0->cirq) (6.5.7)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert->cirq-ft==1.3.0->cirq) (2.6)\n",
            "Collecting httpcore<0.17.0,>=0.15.0 (from httpx<0.24.0,>=0.23.0->qcs-api-client<0.22.0,>=0.21.0->pyquil<4.0.0,>=3.2.0->cirq-rigetti==1.3.0->cirq)\n",
            "  Downloading httpcore-0.16.3-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting rfc3986<2,>=1.3 (from rfc3986[idna2008]<2,>=1.3->httpx<0.24.0,>=0.23.0->qcs-api-client<0.22.0,>=0.21.0->pyquil<4.0.0,>=3.2.0->cirq-rigetti==1.3.0->cirq)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx<0.24.0,>=0.23.0->qcs-api-client<0.22.0,>=0.21.0->pyquil<4.0.0,>=3.2.0->cirq-rigetti==1.3.0->cirq) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets->cirq-ft==1.3.0->cirq) (0.8.4)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->cirq-ft==1.3.0->cirq) (23.1.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->cirq-ft==1.3.0->cirq) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->cirq-ft==1.3.0->cirq) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->cirq-ft==1.3.0->cirq) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->cirq-ft==1.3.0->cirq) (1.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets->cirq-ft==1.3.0->cirq) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets->cirq-ft==1.3.0->cirq) (0.2.13)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml->rpcq<4.0.0,>=3.10.0->pyquil<4.0.0,>=3.2.0->cirq-rigetti==1.3.0->cirq)\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore<0.17.0,>=0.15.0->httpx<0.24.0,>=0.23.0->qcs-api-client<0.22.0,>=0.21.0->pyquil<4.0.0,>=3.2.0->cirq-rigetti==1.3.0->cirq) (0.14.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from httpcore<0.17.0,>=0.15.0->httpx<0.24.0,>=0.23.0->qcs-api-client<0.22.0,>=0.21.0->pyquil<4.0.0,>=3.2.0->cirq-rigetti==1.3.0->cirq) (4.9.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->cirq-ft==1.3.0->cirq) (0.2.4)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->cirq-ft==1.3.0->cirq) (21.2.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->cirq-ft==1.3.0->cirq) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->cirq-ft==1.3.0->cirq) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->cirq-ft==1.3.0->cirq) (2.22)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->cirq-ft==1.3.0->cirq) (1.8.0)\n",
            "Downloading tensorflow-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.3/475.3 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_quantum-0.7.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cirq_core-1.3.0-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cirq_google-1.3.0-py3-none-any.whl (598 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m598.8/598.8 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cirq-1.3.0-py3-none-any.whl (8.1 kB)\n",
            "Downloading cirq_aqt-1.3.0-py3-none-any.whl (27 kB)\n",
            "Downloading cirq_ft-1.3.0-py3-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cirq_ionq-1.3.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cirq_pasqal-1.3.0-py3-none-any.whl (31 kB)\n",
            "Downloading cirq_rigetti-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cirq_web-1.3.0-py3-none-any.whl (596 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m596.5/596.5 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.6-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m89.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading duet-0.2.9-py3-none-any.whl (29 kB)\n",
            "Downloading pyquil-3.5.4-py3-none-any.whl (223 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.8/223.8 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio_status-1.62.3-py3-none-any.whl (14 kB)\n",
            "Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.4/90.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qcs_api_client-0.21.6-py3-none-any.whl (151 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading types_deprecated-1.2.15.20250304-py3-none-any.whl (8.6 kB)\n",
            "Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl (14 kB)\n",
            "Downloading types_retry-0.9.9.20250322-py3-none-any.whl (7.7 kB)\n",
            "Downloading httpx-0.23.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading iso8601-1.1.0-py3-none-any.whl (9.9 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-1.10.21-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyrsistent-0.20.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (120 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Downloading rfc3339-6.2-py3-none-any.whl (5.5 kB)\n",
            "Downloading python_rapidjson-1.20-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml-0.18.10-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-0.16.3-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: lark, rpcq\n",
            "  Building wheel for lark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lark: filename=lark-0.11.3-py2.py3-none-any.whl size=99634 sha256=ed7af5095f20a75f4638594ecf4f7f9ceee6bca5fa8cb346d9e00a6626409f4c\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/2d/0c/bc59f2ef963941700ede6884fa79a90068ca533c9749d5cbf6\n",
            "  Building wheel for rpcq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rpcq: filename=rpcq-3.11.0-py3-none-any.whl size=45967 sha256=6bba9093ad2df4968258ee08cb2ca4ebf6bf102f362bd23fda0bbbb022b610e8\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/b6/ad/8f05ac735661e828024c764a6e6fc3eb6f84434e408aad5eab\n",
            "Successfully built lark rpcq\n",
            "Installing collected packages: rfc3986, rfc3339, lark, wrapt, types-retry, types-python-dateutil, types-deprecated, tensorflow-estimator, tenacity, sympy, ruamel.yaml.clib, retrying, python-rapidjson, pyrsistent, pydantic, protobuf, numpy, keras, jedi, iso8601, duet, attrs, ruamel.yaml, ml-dtypes, jsonschema, httpcore, rpcq, httpx, grpcio-status, tensorboard, qcs-api-client, cirq-core, tensorflow, pyquil, cirq-web, cirq-pasqal, cirq-ionq, cirq-google, cirq-aqt, tensorflow-quantum, cirq-rigetti, cirq-ft, cirq\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.10.6\n",
            "    Uninstalling pydantic-2.10.6:\n",
            "      Successfully uninstalled pydantic-2.10.6\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 25.3.0\n",
            "    Uninstalling attrs-25.3.0:\n",
            "      Successfully uninstalled attrs-25.3.0\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.23.0\n",
            "    Uninstalling jsonschema-4.23.0:\n",
            "      Successfully uninstalled jsonschema-4.23.0\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 1.0.7\n",
            "    Uninstalling httpcore-1.0.7:\n",
            "      Successfully uninstalled httpcore-1.0.7\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "  Attempting uninstall: grpcio-status\n",
            "    Found existing installation: grpcio-status 1.71.0\n",
            "    Uninstalling grpcio-status-1.71.0:\n",
            "      Successfully uninstalled grpcio-status-1.71.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.18.0\n",
            "    Uninstalling tensorflow-2.18.0:\n",
            "      Successfully uninstalled tensorflow-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorstore 0.1.72 requires ml_dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "wandb 0.19.8 requires pydantic<3,>=2.6, but you have pydantic 1.10.21 which is incompatible.\n",
            "referencing 0.36.2 requires attrs>=22.2.0, but you have attrs 21.4.0 which is incompatible.\n",
            "langchain-core 0.3.47 requires pydantic<3.0.0,>=2.5.2; python_full_version < \"3.12.4\", but you have pydantic 1.10.21 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.15.0 which is incompatible.\n",
            "jax 0.5.2 requires ml_dtypes>=0.4.0, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "albumentations 2.0.5 requires pydantic>=2.9.2, but you have pydantic 1.10.21 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.15.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires sympy==1.13.1; python_version >= \"3.9\", but you have sympy 1.12 which is incompatible.\n",
            "langchain 0.3.21 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 1.10.21 which is incompatible.\n",
            "google-genai 1.7.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.23.3 which is incompatible.\n",
            "google-genai 1.7.0 requires pydantic<3.0.0,>=2.0.0, but you have pydantic 1.10.21 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed attrs-21.4.0 cirq-1.3.0 cirq-aqt-1.3.0 cirq-core-1.3.0 cirq-ft-1.3.0 cirq-google-1.3.0 cirq-ionq-1.3.0 cirq-pasqal-1.3.0 cirq-rigetti-1.3.0 cirq-web-1.3.0 duet-0.2.9 grpcio-status-1.62.3 httpcore-0.16.3 httpx-0.23.3 iso8601-1.1.0 jedi-0.19.2 jsonschema-4.17.3 keras-2.15.0 lark-0.11.3 ml-dtypes-0.2.0 numpy-1.26.4 protobuf-4.25.6 pydantic-1.10.21 pyquil-3.5.4 pyrsistent-0.20.0 python-rapidjson-1.20 qcs-api-client-0.21.6 retrying-1.3.4 rfc3339-6.2 rfc3986-1.5.0 rpcq-3.11.0 ruamel.yaml-0.18.10 ruamel.yaml.clib-0.2.12 sympy-1.12 tenacity-8.5.0 tensorboard-2.15.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0 tensorflow-quantum-0.7.3 types-deprecated-1.2.15.20250304 types-python-dateutil-2.9.0.20241206 types-retry-0.9.9.20250322 wrapt-1.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_quantum as tfq\n",
        "import cirq\n",
        "import sympy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n"
      ],
      "metadata": {
        "id": "paslMs3Sx63I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "47126ba8-d280-47aa-91b4-892e01fcefcd"
      },
      "id": "paslMs3Sx63I",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RecursionError",
          "evalue": "maximum recursion depth exceeded while getting the repr of an object",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-9a432f0975ef>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_quantum\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcirq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0m_tf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__internal__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__operators__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/_api/v2/__internal__/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_ctx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontrol_status_ctx\u001b[0m \u001b[0;31m# line: 34\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_convert\u001b[0m \u001b[0;31m# line: 493\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/core/ag_ctx.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mag_logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_export\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_managers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontrol_dependency_on_returns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0malias_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_list\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdynamic_list_append\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/utils/context_managers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_array_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmonitoring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmonitoring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_conversion_registry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/dtypes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mml_dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ml_dtypes/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mml_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_custom_floats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mint4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mml_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_custom_floats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muint4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mml_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finfo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfinfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mml_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iinfo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0miinfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ml_dtypes/_finfo.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0m_bfloat16_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbfloat16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0m_float8_e4m3b11fnuz_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat8_e4m3b11fnuz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0m_float8_e4m3fn_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat8_e4m3fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/core/_dtype.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0marg_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_construction_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_align\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misalignedstruct\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0marg_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_str\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\", align=True\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/core/_dtype.py\u001b[0m in \u001b[0;36m_construction_repr\u001b[0;34m(dtype, include_align, short)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_subarray_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_scalar_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshort\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/core/_dtype.py\u001b[0m in \u001b[0;36m_scalar_str\u001b[0;34m(dtype, short)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"'%sm8%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbyteorder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_datetime_metadata_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;31m# Short repr with endianness, like '<f8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshort\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyteorder\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'|'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/_core/numerictypes.py\u001b[0m in \u001b[0;36missubdtype\u001b[0;34m(arg1, arg2)\u001b[0m\n",
            "... last 4 frames repeated, from the frame below ...\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/core/_dtype.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0marg_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_construction_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_align\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misalignedstruct\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0marg_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_str\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\", align=True\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded while getting the repr of an object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cirq\n",
        "import sympy\n",
        "import tensorflow as tf\n",
        "import tensorflow_quantum as tfq\n",
        "\n"
      ],
      "metadata": {
        "id": "g0oZzqwffMkJ"
      },
      "id": "g0oZzqwffMkJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "vision transformer"
      ],
      "metadata": {
        "id": "2EqQBIrdCwnk"
      },
      "id": "2EqQBIrdCwnk"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vit-pytorch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqVgSkfpDOdD",
        "outputId": "346cda6f-df56-4374-d039-e8f939cc5eb8"
      },
      "id": "uqVgSkfpDOdD",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vit-pytorch\n",
            "  Downloading vit_pytorch-1.10.1-py3-none-any.whl.metadata (69 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/69.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: einops>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from vit-pytorch) (0.8.1)\n",
            "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.11/dist-packages (from vit-pytorch) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from vit-pytorch) (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->vit-pytorch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->vit-pytorch) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->vit-pytorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->vit-pytorch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->vit-pytorch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.10->vit-pytorch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.10->vit-pytorch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.10->vit-pytorch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.10->vit-pytorch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.10->vit-pytorch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.10->vit-pytorch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.10->vit-pytorch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.10->vit-pytorch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.10->vit-pytorch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->vit-pytorch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->vit-pytorch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->vit-pytorch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.10->vit-pytorch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->vit-pytorch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->vit-pytorch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10->vit-pytorch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->vit-pytorch) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->vit-pytorch) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10->vit-pytorch) (3.0.2)\n",
            "Downloading vit_pytorch-1.10.1-py3-none-any.whl (140 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.8/140.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, vit-pytorch\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 vit-pytorch-1.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CLASSICAL VISION TRANSFORMER**"
      ],
      "metadata": {
        "id": "xh9E-w38S5de"
      },
      "id": "xh9E-w38S5de"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code is run in this cell, explaination is below"
      ],
      "metadata": {
        "id": "YCXjN-L3RpGp"
      },
      "id": "YCXjN-L3RpGp"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from vit_pytorch import ViT  # Using a simple ViT library\n",
        "\n",
        "# Check for GPU availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load MNIST dataset\n",
        "transform = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])\n",
        "train_dataset = torchvision.datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root=\"./data\", train=False, transform=transform, download=True)\n",
        "\n",
        "# Use smaller batch size and enable data loading optimizations\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
        "\n",
        "# Define Vision Transformer model with reduced complexity\n",
        "model = ViT(\n",
        "    image_size=32,  # Resized MNIST images\n",
        "    patch_size=4,   # Patch size 4x4\n",
        "    num_classes=10,  # MNIST has 10 digits\n",
        "    dim=32,         # Smaller embedding dimension\n",
        "    depth=3,        # Fewer transformer blocks\n",
        "    heads=4,        # Fewer attention heads\n",
        "    mlp_dim=64,     # Smaller MLP dimension\n",
        "    channels=1\n",
        ")\n",
        "\n",
        "# Move model to the GPU if available\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)  # Reduced learning rate\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(5):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "        # Move data to GPU if available\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Print loss every 100 batches\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f\"Batch [{batch_idx}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/5] Average Loss: {running_loss / len(train_loader):.4f}\")\n",
        "\n",
        "# Evaluate on test set\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Y1E3uRKCujE",
        "outputId": "6d2dfde5-2444-4703-8125-a5043f4932e0"
      },
      "id": "6Y1E3uRKCujE",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch [0/1875], Loss: 2.3973\n",
            "Batch [100/1875], Loss: 2.3160\n",
            "Batch [200/1875], Loss: 2.1124\n",
            "Batch [300/1875], Loss: 1.3297\n",
            "Batch [400/1875], Loss: 0.9479\n",
            "Batch [500/1875], Loss: 0.6999\n",
            "Batch [600/1875], Loss: 0.8603\n",
            "Batch [700/1875], Loss: 0.6135\n",
            "Batch [800/1875], Loss: 0.5279\n",
            "Batch [900/1875], Loss: 0.4108\n",
            "Batch [1000/1875], Loss: 0.3559\n",
            "Batch [1100/1875], Loss: 0.5456\n",
            "Batch [1200/1875], Loss: 0.3319\n",
            "Batch [1300/1875], Loss: 0.3621\n",
            "Batch [1400/1875], Loss: 0.3877\n",
            "Batch [1500/1875], Loss: 0.3034\n",
            "Batch [1600/1875], Loss: 0.1866\n",
            "Batch [1700/1875], Loss: 0.1797\n",
            "Batch [1800/1875], Loss: 0.2911\n",
            "Epoch [1/5] Average Loss: 0.7698\n",
            "Batch [0/1875], Loss: 0.2091\n",
            "Batch [100/1875], Loss: 0.2907\n",
            "Batch [200/1875], Loss: 0.1918\n",
            "Batch [300/1875], Loss: 0.3417\n",
            "Batch [400/1875], Loss: 0.0842\n",
            "Batch [500/1875], Loss: 0.1718\n",
            "Batch [600/1875], Loss: 0.2571\n",
            "Batch [700/1875], Loss: 0.1794\n",
            "Batch [800/1875], Loss: 0.1627\n",
            "Batch [900/1875], Loss: 0.2579\n",
            "Batch [1000/1875], Loss: 0.2179\n",
            "Batch [1100/1875], Loss: 0.1705\n",
            "Batch [1200/1875], Loss: 0.3403\n",
            "Batch [1300/1875], Loss: 0.1862\n",
            "Batch [1400/1875], Loss: 0.3979\n",
            "Batch [1500/1875], Loss: 0.2754\n",
            "Batch [1600/1875], Loss: 0.3652\n",
            "Batch [1700/1875], Loss: 0.0845\n",
            "Batch [1800/1875], Loss: 0.1187\n",
            "Epoch [2/5] Average Loss: 0.2198\n",
            "Batch [0/1875], Loss: 0.1005\n",
            "Batch [100/1875], Loss: 0.1833\n",
            "Batch [200/1875], Loss: 0.1065\n",
            "Batch [300/1875], Loss: 0.1706\n",
            "Batch [400/1875], Loss: 0.1051\n",
            "Batch [500/1875], Loss: 0.2843\n",
            "Batch [600/1875], Loss: 0.1548\n",
            "Batch [700/1875], Loss: 0.1019\n",
            "Batch [800/1875], Loss: 0.1192\n",
            "Batch [900/1875], Loss: 0.0989\n",
            "Batch [1000/1875], Loss: 0.0697\n",
            "Batch [1100/1875], Loss: 0.1815\n",
            "Batch [1200/1875], Loss: 0.1246\n",
            "Batch [1300/1875], Loss: 0.1112\n",
            "Batch [1400/1875], Loss: 0.1713\n",
            "Batch [1500/1875], Loss: 0.0671\n",
            "Batch [1600/1875], Loss: 0.0284\n",
            "Batch [1700/1875], Loss: 0.2036\n",
            "Batch [1800/1875], Loss: 0.0207\n",
            "Epoch [3/5] Average Loss: 0.1576\n",
            "Batch [0/1875], Loss: 0.0466\n",
            "Batch [100/1875], Loss: 0.2279\n",
            "Batch [200/1875], Loss: 0.2273\n",
            "Batch [300/1875], Loss: 0.2491\n",
            "Batch [400/1875], Loss: 0.0504\n",
            "Batch [500/1875], Loss: 0.0499\n",
            "Batch [600/1875], Loss: 0.2609\n",
            "Batch [700/1875], Loss: 0.1206\n",
            "Batch [800/1875], Loss: 0.1677\n",
            "Batch [900/1875], Loss: 0.2775\n",
            "Batch [1000/1875], Loss: 0.2538\n",
            "Batch [1100/1875], Loss: 0.0426\n",
            "Batch [1200/1875], Loss: 0.2188\n",
            "Batch [1300/1875], Loss: 0.1482\n",
            "Batch [1400/1875], Loss: 0.0251\n",
            "Batch [1500/1875], Loss: 0.1992\n",
            "Batch [1600/1875], Loss: 0.2216\n",
            "Batch [1700/1875], Loss: 0.0512\n",
            "Batch [1800/1875], Loss: 0.1256\n",
            "Epoch [4/5] Average Loss: 0.1304\n",
            "Batch [0/1875], Loss: 0.0568\n",
            "Batch [100/1875], Loss: 0.0791\n",
            "Batch [200/1875], Loss: 0.2005\n",
            "Batch [300/1875], Loss: 0.1222\n",
            "Batch [400/1875], Loss: 0.1786\n",
            "Batch [500/1875], Loss: 0.0716\n",
            "Batch [600/1875], Loss: 0.1250\n",
            "Batch [700/1875], Loss: 0.0209\n",
            "Batch [800/1875], Loss: 0.1873\n",
            "Batch [900/1875], Loss: 0.0388\n",
            "Batch [1000/1875], Loss: 0.0353\n",
            "Batch [1100/1875], Loss: 0.0809\n",
            "Batch [1200/1875], Loss: 0.0238\n",
            "Batch [1300/1875], Loss: 0.0123\n",
            "Batch [1400/1875], Loss: 0.0145\n",
            "Batch [1500/1875], Loss: 0.0330\n",
            "Batch [1600/1875], Loss: 0.0250\n",
            "Batch [1700/1875], Loss: 0.0763\n",
            "Batch [1800/1875], Loss: 0.0093\n",
            "Epoch [5/5] Average Loss: 0.1125\n",
            "Test Accuracy: 95.94%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### **1. Importing Necessary Libraries**\n",
        "\n",
        "```python\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from vit_pytorch import ViT  # Using a simple ViT library\n"
      ],
      "metadata": {
        "id": "osHShvZARvev"
      },
      "id": "osHShvZARvev",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line checks if a GPU (CUDA) is available. If it is, the model will run on the GPU to take advantage of hardware acceleration; otherwise, it will run on the CPU. The device object will be used to move data and the model to the appropriate hardware."
      ],
      "metadata": {
        "id": "qmX6dl84THen"
      },
      "id": "qmX6dl84THen"
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "kThURj7_RlEh"
      },
      "id": "kThURj7_RlEh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*transforms.Compose: A function that chains multiple image transformation operations. Here, we first resize the images to 32x32 pixels and then convert them to PyTorch tensors.\n",
        "\n",
        "*train_dataset and test_dataset: These are PyTorch Dataset objects for the training and testing data of the MNIST dataset. The images are resized and converted to tensors as part of the transformation process."
      ],
      "metadata": {
        "id": "aAaRvqdTTOZv"
      },
      "id": "aAaRvqdTTOZv"
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])\n",
        "train_dataset = torchvision.datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root=\"./data\", train=False, transform=transform, download=True)\n"
      ],
      "metadata": {
        "id": "IrmKFM9PSaEA"
      },
      "id": "IrmKFM9PSaEA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-DataLoader: This is used to load the dataset in batches. The training data (train_loader) is shuffled to introduce randomness, while the test data (test_loader) is not shuffled.\n",
        "\n",
        "-batch_size=32: Specifies that each batch will contain 32 images. This helps in efficient training, as processing smaller batches at a time is faster and requires less memory.\n",
        "\n",
        "-num_workers=4: Defines the number of subprocesses to use for data loading, improving loading speed."
      ],
      "metadata": {
        "id": "ow_Hm9AHTO4j"
      },
      "id": "ow_Hm9AHTO4j"
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n"
      ],
      "metadata": {
        "id": "8MFdBNLUSaAd"
      },
      "id": "8MFdBNLUSaAd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ViT (Vision Transformer): The ViT is a deep learning model that divides an image into fixed-size patches, flattens them, and processes them as a sequence using self-attention mechanisms. The parameters in the ViT constructor:\n",
        "\n",
        "-image_size=32: The input image size, which is 32x32 after resizing.\n",
        "\n",
        "-patch_size=4: The image is split into 4x4 patches.\n",
        "\n",
        "-num_classes=10: Since MNIST has 10 digits (0-9), the model will output 10 classes.\n",
        "\n",
        "-dim=32: The embedding dimension is set to 32, reducing model complexity.\n",
        "\n",
        "-depth=3: The number of transformer blocks (layers) is reduced to 3 for efficiency.\n",
        "\n",
        "-heads=4: The number of attention heads is set to 4.\n",
        "\n",
        "-mlp_dim=64: The dimension of the multi-layer perceptron (MLP) layers is set to 64.\n",
        "\n",
        "-channels=1: MNIST images are grayscale, so there is only 1 channel."
      ],
      "metadata": {
        "id": "4bGVzVJQTPg2"
      },
      "id": "4bGVzVJQTPg2"
    },
    {
      "cell_type": "code",
      "source": [
        "model = ViT(\n",
        "    image_size=32,  # Resized MNIST images\n",
        "    patch_size=4,   # Patch size 4x4\n",
        "    num_classes=10,  # MNIST has 10 digits\n",
        "    dim=32,         # Smaller embedding dimension\n",
        "    depth=3,        # Fewer transformer blocks\n",
        "    heads=4,        # Fewer attention heads\n",
        "    mlp_dim=64,     # Smaller MLP dimension\n",
        "    channels=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "sMtZZ8sLSZ9-"
      },
      "id": "sMtZZ8sLSZ9-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This moves the model to the device (either GPU or CPU) to enable faster computation during training and inference."
      ],
      "metadata": {
        "id": "idjx1XHiTQI9"
      },
      "id": "idjx1XHiTQI9"
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n"
      ],
      "metadata": {
        "id": "SS-USozgSZ7f"
      },
      "id": "SS-USozgSZ7f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-criterion = nn.CrossEntropyLoss(): This is the loss function used for multi-class classification tasks. It calculates the difference between the predicted class probabilities and the true labels.\n",
        "\n",
        "-optimizer = optim.Adam(model.parameters(), lr=0.0001): The Adam optimizer is used to update the model’s parameters during training. The learning rate is set to 0.0001 for better stability."
      ],
      "metadata": {
        "id": "QpGQH3m2TQuN"
      },
      "id": "QpGQH3m2TQuN"
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)  # Reduced learning rate\n"
      ],
      "metadata": {
        "id": "ERULCVgFSZ5G"
      },
      "id": "ERULCVgFSZ5G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-Epoch Loop: The training process runs for 5 epochs. Each epoch represents one full pass through the entire training dataset.\n",
        "\n",
        "-Model in Training Mode: model.train() sets the model to training mode, enabling behaviors like dropout.\n",
        "\n",
        "For Each Batch:\n",
        "\n",
        "*Move Data to Device: Images and labels are moved to the appropriate device (GPU/CPU).\n",
        "\n",
        "*Zero Gradients: optimizer.zero_grad() clears old gradients from the previous step.\n",
        "\n",
        "*Forward Pass: The model processes the input images and generates predictions.\n",
        "\n",
        "*Loss Calculation: The CrossEntropyLoss function compares the predictions and true labels.\n",
        "\n",
        "*Backward Pass: loss.backward() computes the gradients.\n",
        "\n",
        "*Optimizer Step: optimizer.step() updates the model’s parameters using the computed gradients.\n",
        "\n",
        "*Loss Logging: Every 100 batches, the current batch loss is printed, and after each epoch, the average loss is printed."
      ],
      "metadata": {
        "id": "jf-E6k5pTRVW"
      },
      "id": "jf-E6k5pTRVW"
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(5):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f\"Batch [{batch_idx}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/5] Average Loss: {running_loss / len(train_loader):.4f}\")\n"
      ],
      "metadata": {
        "id": "_tKWGTlkSZ2Q"
      },
      "id": "_tKWGTlkSZ2Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-Model in Evaluation Mode: model.eval() sets the model to evaluation mode, disabling behaviors like dropout.\n",
        "\n",
        "No Gradient Calculation: torch.no_grad() ensures that gradients are not computed during inference, which saves memory and computational resources.\n",
        "\n",
        "For Each Batch in Test Set:\n",
        "\n",
        "Move Data to Device: Images and labels are moved to the device.\n",
        "\n",
        "Forward Pass: The model predicts the class labels for the input images.\n",
        "\n",
        "Predicted Class: torch.max() returns the class with the highest probability.\n",
        "\n",
        "Correct Predictions: The number of correct predictions is counted.\n",
        "\n",
        "Accuracy Calculation: The accuracy is calculated by dividing the correct predictions by the total number of samples."
      ],
      "metadata": {
        "id": "r-LsAs_PTR9S"
      },
      "id": "r-LsAs_PTR9S"
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "id": "BnlbXLHOSrbY"
      },
      "id": "BnlbXLHOSrbY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUANTUM VISION TRANSFORMER**"
      ],
      "metadata": {
        "id": "r20Sk-qxTCa_"
      },
      "id": "r20Sk-qxTCa_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extending Classical ViT to Quantum ViT**\n",
        "A classical Vision Transformer (ViT) processes image patches using self-attention mechanisms and MLP layers. To extend this to a quantum Vision Transformer (QViT), we can replace certain key components with quantum-based operations:\n",
        "\n",
        "**Quantum Embeddings**\n",
        "\n",
        "Instead of traditional linear embeddings for image patches, we can encode image data into quantum states using amplitude encoding or angle encoding.\n",
        "\n",
        "**Quantum Self-Attention Mechanism**\n",
        "\n",
        "The multi-head self-attention in classical ViT can be replaced with a quantum self-attention mechanism using parameterized quantum circuits (PQCs).\n",
        "\n",
        "**Quantum circuits** can perform non-trivial transformations in high-dimensional Hilbert space, potentially improving feature extraction.\n",
        "\n",
        "**Quantum Feedforward Network**\n",
        "\n",
        "The MLP layers in ViT can be substituted with quantum variational circuits, enhancing expressivity with fewer parameters.\n",
        "\n",
        "**Hybrid Quantum-Classical Architecture**\n",
        "\n",
        "A hybrid approach can be adopted where the feature extraction is performed using quantum layers, while the classification head remains classical."
      ],
      "metadata": {
        "id": "VYGhVdIvpP1F"
      },
      "id": "VYGhVdIvpP1F"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pennylane\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwCV9bNNL5PS",
        "outputId": "b81fa790-386e-4a7a-f5b2-05768658bdd4"
      },
      "id": "dwCV9bNNL5PS",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pennylane\n",
            "  Downloading PennyLane-0.40.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy<2.1 in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pennylane) (3.4.2)\n",
            "Collecting rustworkx>=0.14.0 (from pennylane)\n",
            "  Downloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.7.0)\n",
            "Collecting tomlkit (from pennylane)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting appdirs (from pennylane)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting autoray>=0.6.11 (from pennylane)\n",
            "  Downloading autoray-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from pennylane) (5.5.2)\n",
            "Collecting pennylane-lightning>=0.40 (from pennylane)\n",
            "  Downloading PennyLane_Lightning-0.40.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (27 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from pennylane) (4.13.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pennylane) (24.2)\n",
            "Collecting diastatic-malt (from pennylane)\n",
            "  Downloading diastatic_malt-2.15.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting scipy-openblas32>=0.3.26 (from pennylane-lightning>=0.40->pennylane)\n",
            "  Downloading scipy_openblas32-0.3.29.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: astunparse in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (1.6.3)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (0.6.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (2.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2025.1.31)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (1.17.0)\n",
            "Downloading PennyLane-0.40.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autoray-0.7.1-py3-none-any.whl (930 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.8/930.8 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PennyLane_Lightning-0.40.0-cp311-cp311-manylinux_2_28_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading diastatic_malt-2.15.2-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading scipy_openblas32-0.3.29.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: appdirs, tomlkit, scipy-openblas32, rustworkx, autoray, diastatic-malt, pennylane-lightning, pennylane\n",
            "Successfully installed appdirs-1.4.4 autoray-0.7.1 diastatic-malt-2.15.2 pennylane-0.40.0 pennylane-lightning-0.40.0 rustworkx-0.16.0 scipy-openblas32-0.3.29.0.0 tomlkit-0.13.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import pennylane as qml\n",
        "\n",
        "print(\"Initializing Quantum Vision Transformer...\")\n",
        "\n",
        "# Load MNIST dataset\n",
        "print(\"Loading MNIST dataset...\")\n",
        "transform = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])\n",
        "train_dataset = torchvision.datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root=\"./data\", train=False, transform=transform, download=True)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "print(\"MNIST dataset loaded successfully.\")\n",
        "\n",
        "# Define Quantum Circuit\n",
        "num_qubits = 4  # Set number of qubits\n",
        "dev = qml.device(\"default.qubit\", wires=num_qubits)\n",
        "\n",
        "@qml.qnode(dev, interface=\"torch\")\n",
        "def quantum_circuit(inputs, weights):\n",
        "    qml.AngleEmbedding(inputs, wires=range(num_qubits))\n",
        "    qml.BasicEntanglerLayers(weights, wires=range(num_qubits))\n",
        "    return [qml.expval(qml.PauliZ(w)) for w in range(num_qubits)]\n",
        "\n",
        "class QuantumLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.weights = nn.Parameter(0.01 * torch.randn(3, num_qubits))  # Trainable weights\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.shape[0], -1)[:, :num_qubits]  # Flatten input & pick first `num_qubits` values\n",
        "        q_outs = [torch.tensor(quantum_circuit(x[i], self.weights), dtype=torch.float32) for i in range(x.shape[0])]\n",
        "        return torch.stack(q_outs)\n",
        "\n",
        "# Define Hybrid Vision Transformer\n",
        "class HybridViT(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(1, 8, kernel_size=3, stride=1, padding=1)  # Initial feature extraction\n",
        "        self.quantum_layer = QuantumLayer()\n",
        "        self.fc = nn.Linear(num_qubits, 10)  # Final classification layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = torch.mean(x, dim=(2, 3))  # Global averaging for feature reduction\n",
        "        x = self.quantum_layer(x)\n",
        "        return self.fc(x)\n",
        "\n",
        "print(\"Initializing model...\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = HybridViT().to(device)\n",
        "print(f\"Model initialized and running on: {device}\")\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 2\n",
        "print(\"Starting training...\")\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if (batch_idx + 1) % 100 == 0:  # Print every 100 batches\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] completed with Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "# Evaluate on test set\n",
        "print(\"Evaluating model...\")\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2GpizvLCugE",
        "outputId": "82cc2f00-cc40-4304-8455-747e940e5ec0"
      },
      "id": "M2GpizvLCugE",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Quantum Vision Transformer...\n",
            "Loading MNIST dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 53.7MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 2.59MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 15.6MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.13MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNIST dataset loaded successfully.\n",
            "Initializing model...\n",
            "Model initialized and running on: cpu\n",
            "Starting training...\n",
            "Epoch [1/2], Step [100/938], Loss: 2.3719\n",
            "Epoch [1/2], Step [200/938], Loss: 2.2946\n",
            "Epoch [1/2], Step [300/938], Loss: 2.3153\n",
            "Epoch [1/2], Step [400/938], Loss: 2.2930\n",
            "Epoch [1/2], Step [500/938], Loss: 2.3032\n",
            "Epoch [1/2], Step [600/938], Loss: 2.3159\n",
            "Epoch [1/2], Step [700/938], Loss: 2.3096\n",
            "Epoch [1/2], Step [800/938], Loss: 2.3182\n",
            "Epoch [1/2], Step [900/938], Loss: 2.3056\n",
            "Epoch [1/2] completed with Average Loss: 2.3131\n",
            "Epoch [2/2], Step [100/938], Loss: 2.3066\n",
            "Epoch [2/2], Step [200/938], Loss: 2.3086\n",
            "Epoch [2/2], Step [300/938], Loss: 2.2972\n",
            "Epoch [2/2], Step [400/938], Loss: 2.3000\n",
            "Epoch [2/2], Step [500/938], Loss: 2.2894\n",
            "Epoch [2/2], Step [600/938], Loss: 2.3020\n",
            "Epoch [2/2], Step [700/938], Loss: 2.3024\n",
            "Epoch [2/2], Step [800/938], Loss: 2.2975\n",
            "Epoch [2/2], Step [900/938], Loss: 2.2930\n",
            "Epoch [2/2] completed with Average Loss: 2.3014\n",
            "Evaluating model...\n",
            "Test Accuracy: 11.35%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### **1. Importing Necessary Libraries**\n",
        "\n",
        "```python\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import pennylane as qml\n"
      ],
      "metadata": {
        "id": "jmh3BKjiZ06p"
      },
      "id": "jmh3BKjiZ06p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-Dataset: Loads MNIST, resizes the images to 32x32, and converts them to tensors.\n",
        "\n",
        "-DataLoader: Efficiently loads data in batches for training and testing. The batch size is set to 64, and data loading is parallelized (num_workers=4).\n",
        "\n"
      ],
      "metadata": {
        "id": "TvhADJmjUZc9"
      },
      "id": "TvhADJmjUZc9"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading MNIST dataset...\")\n",
        "transform = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])\n",
        "train_dataset = torchvision.datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root=\"./data\", train=False, transform=transform, download=True)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n"
      ],
      "metadata": {
        "id": "KuT9QuinUYg1"
      },
      "id": "KuT9QuinUYg1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quantum Circuit**: The quantum circuit is defined using PennyLane:\n",
        "\n",
        "-AngleEmbedding: Embeds classical data (MNIST features) into quantum states.\n",
        "\n",
        "-BasicEntanglerLayers: Applies entanglement between qubits.\n",
        "\n",
        "-expval(qml.PauliZ(w)): Measures the Pauli-Z expectation value of each qubit, representing quantum information."
      ],
      "metadata": {
        "id": "wte80PRoUYLt"
      },
      "id": "wte80PRoUYLt"
    },
    {
      "cell_type": "code",
      "source": [
        "num_qubits = 4  # Set number of qubits\n",
        "dev = qml.device(\"default.qubit\", wires=num_qubits)\n",
        "\n",
        "@qml.qnode(dev, interface=\"torch\")\n",
        "def quantum_circuit(inputs, weights):\n",
        "    qml.AngleEmbedding(inputs, wires=range(num_qubits))\n",
        "    qml.BasicEntanglerLayers(weights, wires=range(num_qubits))\n",
        "    return [qml.expval(qml.PauliZ(w)) for w in range(num_qubits)]\n"
      ],
      "metadata": {
        "id": "nP_HISduUa9J"
      },
      "id": "nP_HISduUa9J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quantum Layer**: A custom layer in the neural network that interacts with the quantum circuit.\n",
        "\n",
        "weights: Trainable parameters used by the quantum circuit.\n",
        "\n",
        "forward: Flattens the input, passes it through the quantum circuit, and returns quantum output."
      ],
      "metadata": {
        "id": "1Q6UvwhaUbj9"
      },
      "id": "1Q6UvwhaUbj9"
    },
    {
      "cell_type": "code",
      "source": [
        "class QuantumLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.weights = nn.Parameter(0.01 * torch.randn(3, num_qubits))  # Trainable weights\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.shape[0], -1)[:, :num_qubits]  # Flatten input & pick first `num_qubits` values\n",
        "        q_outs = [torch.tensor(quantum_circuit(x[i], self.weights), dtype=torch.float32) for i in range(x.shape[0])]\n",
        "        return torch.stack(q_outs)\n"
      ],
      "metadata": {
        "id": "md6NSbDwUa5i"
      },
      "id": "md6NSbDwUa5i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hybrid Model**: Combines classical and quantum computing:\n",
        "\n",
        "-conv: A 2D convolutional layer for initial feature extraction from MNIST images.\n",
        "\n",
        "-quantum_layer: A custom quantum layer that processes features using quantum circuits.\n",
        "\n",
        "-fc: A fully connected layer to output predictions for 10 classes (digits 0-9).\n",
        "\n"
      ],
      "metadata": {
        "id": "w_HDM4IjUduR"
      },
      "id": "w_HDM4IjUduR"
    },
    {
      "cell_type": "code",
      "source": [
        "class HybridViT(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(1, 8, kernel_size=3, stride=1, padding=1)  # Initial feature extraction\n",
        "        self.quantum_layer = QuantumLayer()\n",
        "        self.fc = nn.Linear(num_qubits, 10)  # Final classification layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = torch.mean(x, dim=(2, 3))  # Global averaging for feature reduction\n",
        "        x = self.quantum_layer(x)\n",
        "        return self.fc(x)\n"
      ],
      "metadata": {
        "id": "tqHaIoTOUa3W"
      },
      "id": "tqHaIoTOUa3W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-Model Initialization: The model is initialized and moved to the GPU (if available) for faster training.\n",
        "\n",
        "-Device: The model is set to run on either CPU or GPU depending on availability.\n",
        "\n"
      ],
      "metadata": {
        "id": "xNgvUcFLUetI"
      },
      "id": "xNgvUcFLUetI"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Initializing model...\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = HybridViT().to(device)\n",
        "print(f\"Model initialized and running on: {device}\")\n"
      ],
      "metadata": {
        "id": "DItMI_deUa09"
      },
      "id": "DItMI_deUa09",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-CrossEntropyLoss: A common loss function for multi-class classification.\n",
        "\n",
        "-Adam Optimizer: An optimization algorithm used to update model parameters during training."
      ],
      "metadata": {
        "id": "V5XXiL4KUfos"
      },
      "id": "V5XXiL4KUfos"
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "FUQfY6ilUayY"
      },
      "id": "FUQfY6ilUayY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Epoch Loop**: Runs for 2 epochs, where each epoch processes the entire training dataset.\n",
        "\n",
        "**Batch Processing**: For each batch, the model is trained by computing the forward pass, calculating the loss, and updating the weights.\n",
        "\n",
        "**Loss Logging**: Every 100 steps, the current loss is printed. After each epoch, the average loss is displayed."
      ],
      "metadata": {
        "id": "7xzG9AC1UgJW"
      },
      "id": "7xzG9AC1UgJW"
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 2\n",
        "print(\"Starting training...\")\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if (batch_idx + 1) % 100 == 0:  # Print every 100 batches\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] completed with Average Loss: {avg_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "Rdt1r2IYUav8"
      },
      "id": "Rdt1r2IYUav8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Evaluation**: Evaluates the trained model on the test dataset:\n",
        "\n",
        "model.eval(): Sets the model to evaluation mode (disables dropout, etc.).\n",
        "\n",
        "Accuracy Calculation: Compares the predicted labels to the true labels and calculates accuracy"
      ],
      "metadata": {
        "id": "VhX5BAuRUglZ"
      },
      "id": "VhX5BAuRUglZ"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluating model...\")\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "id": "sVU2kaw2Uagb"
      },
      "id": "sVU2kaw2Uagb",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}